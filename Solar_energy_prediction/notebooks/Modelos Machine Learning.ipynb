{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "df_train1 = df_final.loc['1994/01/01':'2003/12/31']\n",
    "df_test = df_final.loc['2004/01/01':'2008/01/01']\n",
    "df_train1.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train1.loc['1994/01/01':'2000/12/31']\n",
    "df_val = df_train1.loc['2001/01/01':'2003/12/31']\n",
    "df_val.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separación de target y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('APAC', axis = 1)\n",
    "y_train = df_train['APAC']\n",
    "X_val = df_val.drop('APAC', axis = 1)\n",
    "y_val = df_val['APAC']\n",
    "X_train_all = df_train1.drop('APAC', axis = 1)\n",
    "y_train_all = df_train1['APAC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV, RandomizedSearchCV\n",
    "split_index = [-1]*len(X_train) + [0]*len(X_val)\n",
    "X = np.concatenate((X_train, X_val), axis=0)\n",
    "y = np.concatenate((y_train, y_val), axis=0)\n",
    "pds = PredefinedSplit(test_fold = split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Pipeline(steps = [\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"reg\", LinearRegression())])\n",
    "ridge = Pipeline(steps = [\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"ridge\", Ridge())])\n",
    "lasso = Pipeline(steps = [\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"Lasso\", Lasso())])\n",
    "svr = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"selectkbest\", SelectKBest()),\n",
    "    (\"svr\", SVR())])\n",
    "\n",
    "rand_forest = RandomForestRegressor()\n",
    "xgb_reg = XGBRegressor(random_state=42)\n",
    "\n",
    "knn_scal = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"knn\", KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "reg_param = {}\n",
    "\n",
    "ridge_param = {'ridge__alpha': np.logspace(-3,3,10)}\n",
    "\n",
    "lasso_param = {'Lasso__alpha': np.logspace(-3,3,10)}\n",
    "\n",
    "svr_param = {\n",
    "    \"selectkbest__k\": [1,2,3,4,5],\n",
    "    \"svr__C\": np.arange(1, 100, 10),\n",
    "    \"svr__epsilon\": np.arange(0.001, 1),\n",
    "    \"svr__kernel\": ['linear', 'rbf', 'poly']\n",
    "    }\n",
    "\n",
    "rand_forest_param = {\n",
    "    'n_estimators': [1350, 1375, 1400, 1425],\n",
    "    'max_features': [4,5,6,7]\n",
    "}\n",
    "\n",
    "xgboost_params = {\n",
    "        'min_child_weight': [8, 10, 12],\n",
    "        'gamma': [1.5, 2, 2.5, 3, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "        'max_depth': [2, 3, 4]\n",
    "        }\n",
    "\n",
    "knn_param_scal = {\n",
    "    'knn__n_neighbors': [3,5,7]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "gs_reg = GridSearchCV(reg,\n",
    "reg_param,\n",
    "cv=pds,\n",
    "scoring = 'neg_mean_absolute_error',\n",
    "n_jobs = -1,\n",
    "verbose = 1)\n",
    "gs_ridge = GridSearchCV(ridge,\n",
    "ridge_param,\n",
    "cv=pds,\n",
    "scoring = 'neg_mean_absolute_error',\n",
    "n_jobs = -1,\n",
    "verbose = 1)\n",
    "gs_lasso = GridSearchCV(lasso,\n",
    "lasso_param,\n",
    "cv=pds,\n",
    "scoring = 'neg_mean_absolute_error',\n",
    "n_jobs = -1,\n",
    "verbose = 1)\n",
    "gs_svr = RandomizedSearchCV(svr,\n",
    "svr_param,\n",
    "cv=pds,\n",
    "scoring = 'neg_mean_absolute_error',\n",
    "n_jobs = -1,\n",
    "verbose = 1, \n",
    "random_state = 42)\n",
    "gs_rand_forest = GridSearchCV(rand_forest,\n",
    "rand_forest_param,\n",
    "cv=pds,\n",
    "scoring = 'neg_mean_absolute_error',\n",
    "n_jobs = -1,\n",
    "verbose = 1)\n",
    "\n",
    "gs_xgb =  GridSearchCV(xgb_reg,\n",
    "xgboost_params,\n",
    "scoring='neg_mean_absolute_error',\n",
    "n_jobs=4,\n",
    "cv=pds,\n",
    "verbose=3) \n",
    "\n",
    "gs_knn_scal = GridSearchCV(knn_scal,\n",
    "knn_param_scal,\n",
    "scoring='neg_mean_absolute_error',\n",
    "cv=pds,\n",
    "verbose=1,\n",
    "n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "grids = {\n",
    "    \"gs_reg\": gs_reg,\n",
    "    \"gs_ridge\": gs_ridge,\n",
    "    \"gs_lasso\": gs_lasso,\n",
    "    \"gs_svr\": gs_svr,\n",
    "    \"gs_rand_forest\": gs_rand_forest,\n",
    "    \"gs_xgb\": gs_xgb,\n",
    "    \"gs_knn_scal\": gs_knn_scal\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "for nombre, grid_search in grids.items():\n",
    "    grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_validation_dummy = np.mean(np.abs(y_val-y_train.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grids = [(i, j.best_score_) for i, j in grids.items()]\n",
    "\n",
    "best_grids = pd.DataFrame(best_grids, columns = [\"Grid\", \"Best score\"])\n",
    "best_grids['Raes'] = (best_grids['Best score'] * (-1))/mae_validation_dummy\n",
    "best_grids.sort_values(by = \"Best score\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo corresponde con random_forest, que dispone de uner error relativo absoluto menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best estimator:\", gs_rand_forest.best_estimator_)\n",
    "print(\"Best params:\", gs_rand_forest.best_params_)\n",
    "print(\"Best score:\", gs_rand_forest.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from pmdarima.arima import auto_arima\n",
    "from pmdarima.arima import ARIMA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = auto_arima(y_train,\n",
    "                   start_p = 1,\n",
    "                   start_q = 1,\n",
    "                   max_p = 5,\n",
    "                   max_q = 5,\n",
    "                   max_d = 3,\n",
    "                   trace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.aic())\n",
    "predictions = model.predict(y_val.shape[0])\n",
    "arima_mae = mean_absolute_error(y_val, predictions)\n",
    "print(\"mean_absolute_error:\", mean_absolute_error(y_val, predictions))\n",
    "print(\"relative_absolute_error:\", arima_mae/mae_validation_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_Serie = df_final[['APAC']].reset_index()\n",
    "time_Serie['Date'] = pd.to_datetime(time_Serie['Date'])\n",
    "time_Serie = time_Serie.set_index('Date')\n",
    "time_Serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result_add = seasonal_decompose(time_Serie, model = \"additive\", extrapolate_trend = \"freq\")\n",
    "\n",
    "plt.rcParams.update({'figure.figsize': (6,6)})\n",
    "result_add.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12,0,-1):\n",
    "    time_Serie[\"t-\"+str(i)] = time_Serie[\"APAC\"].shift(i)\n",
    "\n",
    "\n",
    "time_Serie.dropna(inplace=True)\n",
    "time_Serie.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = time_Serie.iloc[:,1:]\n",
    "y = time_Serie.iloc[:, 0]\n",
    "\n",
    "X_train1 = X.loc['1994/01/01':'2003/12/31']\n",
    "y_train1 = y.loc['1994/01/01':'2003/12/31']\n",
    "X_test = X.loc['2001/01/01':'2003/12/31']\n",
    "y_test = y.loc['2001/01/01':'2003/12/31']\n",
    "\n",
    "X_train = X.loc['1994/01/01':'2000/12/31']\n",
    "y_train = y.loc['1994/01/01':'2000/12/31']\n",
    "\n",
    "X_val = X.loc['2001/01/01':'2003/12/31']\n",
    "y_val = y.loc['2001/01/01':'2003/12/31']\n",
    "\n",
    "\n",
    "print(\"Shape X_train:\", X_train.shape)\n",
    "print(\"Shape X_val\", X_val.shape)\n",
    "print(\"Shape y_train:\", y_train.shape)\n",
    "print(\"Shape y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV, RandomizedSearchCV\n",
    "split_index = [-1]*len(X_train) + [0]*len(X_val)\n",
    "X = np.concatenate((X_train, X_val), axis=0)\n",
    "y = np.concatenate((y_train, y_val), axis=0)\n",
    "pds = PredefinedSplit(test_fold = split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Pipeline(steps = [\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"reg\", LinearRegression())])\n",
    "ridge = Pipeline(steps = [\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"ridge\", Ridge())])\n",
    "lasso = Pipeline(steps = [\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"Lasso\", Lasso())])\n",
    "svr = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"selectkbest\", SelectKBest()),\n",
    "    (\"svr\", SVR())])\n",
    "\n",
    "rand_forest = RandomForestRegressor()\n",
    "xgb_reg = XGBRegressor(random_state=42)\n",
    "\n",
    "knn_scal = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"knn\", KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "reg_param = {}\n",
    "\n",
    "ridge_param = {'ridge__alpha': np.logspace(-3,3,10)}\n",
    "\n",
    "lasso_param = {'Lasso__alpha': np.logspace(-3,3,10)}\n",
    "\n",
    "svr_param = {\n",
    "    \"selectkbest__k\": [1,2,3,4,5,6],\n",
    "    \"svr__C\": np.arange(1, 100, 10),\n",
    "    \"svr__epsilon\": np.arange(0.001, 1),\n",
    "    \"svr__kernel\": ['linear', 'rbf', 'poly']\n",
    "    }\n",
    "\n",
    "rand_forest_param = {\n",
    "    'n_estimators': [1425, 1450, 1475, 1500],\n",
    "    'max_features': [2,3,4,5,6]\n",
    "}\n",
    "\n",
    "xgboost_params = {\n",
    "        'min_child_weight': [8, 10, 12],\n",
    "        'gamma': [1.5, 2, 2.5, 3, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "        'max_depth': [2, 3, 4]\n",
    "        }\n",
    "\n",
    "knn_param_scal = {\n",
    "    'knn__n_neighbors': [3,5,7]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "gs_reg_ts = GridSearchCV(reg,\n",
    "reg_param,\n",
    "cv=pds,\n",
    "scoring = 'neg_mean_absolute_error',\n",
    "n_jobs = -1,\n",
    "verbose = 1)\n",
    "gs_ridge_ts = GridSearchCV(ridge,\n",
    "ridge_param,\n",
    "cv=pds,\n",
    "scoring = 'neg_mean_absolute_error',\n",
    "n_jobs = -1,\n",
    "verbose = 1)\n",
    "gs_lasso_ts = GridSearchCV(lasso,\n",
    "lasso_param,\n",
    "cv=pds,\n",
    "scoring = 'neg_mean_absolute_error',\n",
    "n_jobs = -1,\n",
    "verbose = 1)\n",
    "gs_svr_ts = RandomizedSearchCV(svr,\n",
    "svr_param,\n",
    "cv=pds,\n",
    "scoring = 'neg_mean_absolute_error',\n",
    "n_jobs = -1,\n",
    "verbose = 1, \n",
    "random_state = 42)\n",
    "gs_rand_forest_ts = GridSearchCV(rand_forest,\n",
    "rand_forest_param,\n",
    "cv=pds,\n",
    "scoring = 'neg_mean_absolute_error',\n",
    "n_jobs = -1,\n",
    "verbose = 1)\n",
    "\n",
    "gs_xgb_ts =  GridSearchCV(xgb_reg,\n",
    "xgboost_params,\n",
    "scoring='neg_mean_absolute_error',\n",
    "n_jobs=4,\n",
    "cv=pds,\n",
    "verbose=3) \n",
    "\n",
    "gs_knn_scal_ts = GridSearchCV(knn_scal,\n",
    "knn_param_scal,\n",
    "scoring='neg_mean_absolute_error',\n",
    "cv=pds,\n",
    "verbose=1,\n",
    "n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "grids_ts = {\n",
    "    \"gs_reg_ts\": gs_reg_ts,\n",
    "    \"gs_ridge_ts\": gs_ridge_ts,\n",
    "    \"gs_lasso_ts\": gs_lasso_ts,\n",
    "    \"gs_svr_ts\": gs_svr_ts,\n",
    "    \"gs_rand_forest_ts\": gs_rand_forest_ts,\n",
    "    \"gs_xgb_ts\": gs_xgb_ts,\n",
    "    \"gs_knn_scal_ts\": gs_knn_scal_ts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "for nombre, grid_search in grids_ts.items():\n",
    "    grid_search.fit(X, y)\n",
    "    print(nombre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grids = [(i, j.best_score_) for i, j in grids_ts.items()]\n",
    "\n",
    "best_grids = pd.DataFrame(best_grids, columns = [\"Grid\", \"Best score\"])\n",
    "best_grids['Raes'] = (best_grids['Best score'] * (-1))/mae_validation_dummy\n",
    "best_grids.sort_values(by = \"Best score\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ningún caso nigún modelo de time series mejora al modelo de random forest de regresión en el conjunto de validación.\n",
    "\n",
    "Por lo que a continuación se entrenara este modelo con todo el conjunto de train (train + validacion) y se estudiará su actuación en test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo final y predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop('APAC', axis = 1)\n",
    "y_test = df_test['APAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators= 1400, max_features=5, criterion= 'absolute_error')\n",
    "\n",
    "model.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_validation_dummy_end = np.mean(np.abs(y_test-y_train_all.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mae_end = mean_absolute_error(y_test, y_pred)\n",
    "rae_end = mae_end/mae_validation_dummy_end\n",
    "print(mae_end)\n",
    "print(rae_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = pd.DataFrame(y_test)\n",
    "fin['pred'] = y_pred\n",
    "fin2 = fin.reset_index()\n",
    "fin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual values\n",
    "plt.plot(fin2['Date'], fin2['APAC'], 'b-', label = 'actual')\n",
    "# Plot the predicted values\n",
    "plt.plot(fin2['Date'], fin2['pred'], 'ro', label = 'prediction')\n",
    "plt.xticks(); \n",
    "plt.legend()\n",
    "# Graph labels\n",
    "plt.xlabel('Date'); plt.ylabel('daily incoming solar energy in (J m-2)'); plt.title('Actual and Predicted Values');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo dispone de un error relativo absoluto de 0.32, es decir el modelo mejora en un 68% al modelo trivial, predecir todo con la media del entrenamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76c24f8bc9514c6502187ffd48ecdbbcac9127747815a2c20d554bded54d2871"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
